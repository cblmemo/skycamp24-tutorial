envs:
  BUCKET: YOUR_OWN_BUCKET_NAME # Change to your own bucket name
  HF_TOKEN:

resources:
  accelerators: # Fill in the accelerator type
  cpus: 16+
  memory: 32+

num_nodes: 1

file_mounts:
  /artifacts:
    name: $BUCKET
    store: gcs

workdir: .

setup: |
  # Install LLaMA-Factory
  if [ ! -d "LLaMA-Factory" ]; then
    git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git
  fi
  cd LLaMA-Factory
  git checkout 40ceba500bab7452b8671a9fbcd14bbf4a8f6f37
  pip install -e ".[torch,metrics,deepspeed]"
  # pip install vllm==0.6.2

  # Login to Hugging Face Hub
  python3 -c "import huggingface_hub; huggingface_hub.login('${HF_TOKEN}')"

run: |
  # Create hardcoded questions
  python hardcoded_questions.py
  # Finetune the model
  cd LLaMA-Factory
  FORCE_TORCHRUN=1 llamafactory-cli train ../llama3_full_sft_ds3.yaml
